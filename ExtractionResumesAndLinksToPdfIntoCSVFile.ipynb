{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d85060-362e-402e-898c-28de1b4e018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des résumés en français et en anglais, et le lien vers le mémoire pdf, et le lien permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391389c1-020c-4c30-8a72-6357bb84e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "# URL de la page à scraper\n",
    "url = \"https://www.ressources-actuarielles.net/memoires\"\n",
    "\n",
    "# Fonction pour extraire les données\n",
    "def extraire_memoires():\n",
    "    # Récupération de la page\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erreur lors de la récupération de la page: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Parsing du HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Recherche des articles de mémoires\n",
    "    articles = soup.find_all('article', class_='node--type-memoire')\n",
    "    \n",
    "    resultats = []\n",
    "    \n",
    "    for article in articles:\n",
    "        # Extraction du titre\n",
    "        titre_element = article.find('h2', class_='node__title')\n",
    "        titre = titre_element.text.strip() if titre_element else \"Titre non disponible\"\n",
    "        \n",
    "        # Extraction du lien permanent\n",
    "        lien_permanent = None\n",
    "        if titre_element and titre_element.find('a'):\n",
    "            lien_permanent = \"https://www.ressources-actuarielles.net\" + titre_element.find('a')['href']\n",
    "        \n",
    "        # Extraction du lien PDF\n",
    "        lien_pdf = None\n",
    "        pdf_element = article.find('a', href=re.compile(r'\\.pdf$'))\n",
    "        if pdf_element:\n",
    "            lien_pdf = \"https://www.ressources-actuarielles.net\" + pdf_element['href']\n",
    "        \n",
    "        # Extraction des résumés\n",
    "        resume_fr = \"\"\n",
    "        resume_en = \"\"\n",
    "        \n",
    "        # Chercher les sections de résumé\n",
    "        resume_sections = article.find_all('div', class_='field--type-text-with-summary')\n",
    "        \n",
    "        for section in resume_sections:\n",
    "            # Vérifier si c'est un résumé français ou anglais\n",
    "            label = section.find('div', class_='field__label')\n",
    "            if label:\n",
    "                label_text = label.text.strip().lower()\n",
    "                content = section.find('div', class_='field__item')\n",
    "                \n",
    "                if content:\n",
    "                    if 'français' in label_text or 'resume' in label_text:\n",
    "                        resume_fr = content.text.strip()\n",
    "                    elif 'anglais' in label_text or 'abstract' in label_text:\n",
    "                        resume_en = content.text.strip()\n",
    "        \n",
    "        # Ajouter les données extraites à la liste des résultats\n",
    "        resultats.append({\n",
    "            'Titre': titre,\n",
    "            'Lien Permanent': lien_permanent,\n",
    "            'Lien PDF': lien_pdf,\n",
    "            'Résumé Français': resume_fr,\n",
    "            'Résumé Anglais': resume_en\n",
    "        })\n",
    "        \n",
    "        # Pause pour éviter de surcharger le serveur\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Exécution de la fonction d'extraction\n",
    "memoires = extraire_memoires()\n",
    "\n",
    "# Création d'un DataFrame pandas pour une meilleure visualisation\n",
    "if memoires:\n",
    "    df = pd.DataFrame(memoires)\n",
    "    print(f\"Nombre de mémoires extraits: {len(df)}\")\n",
    "    \n",
    "    # Affichage des 5 premiers résultats\n",
    "    print(\"\\nAperçu des données extraites:\")\n",
    "    print(df[['Titre', 'Lien Permanent', 'Lien PDF']].head())\n",
    "    \n",
    "    # Sauvegarde des résultats dans un fichier CSV\n",
    "    df.to_csv('memoires_actuariels.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"\\nLes données ont été sauvegardées dans 'memoires_actuariels.csv'\")\n",
    "else:\n",
    "    print(\"Échec de l'extraction des données.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
