import requests
from bs4 import BeautifulSoup
import pandas as pd

# URL de la page
url = "https://www.institutdesactuaires.com/se-documenter/memoires/memoires-d-actuariat-4651"

# Envoi de la requête HTTP
headers = {'User-Agent': 'Mozilla/5.0'}
response = requests.get(url, headers=headers)

# Création de l'objet BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Trouver le tableau
table = soup.find('table')

# Listes pour stocker les données
auteurs = []
societes = []
annees = []
titres = []

# Extraction des données du tableau
rows = table.find_all('tr')[1:]  # Skip header row
for row in rows:
    cols = row.find_all('td')
    if len(cols) >= 4:
        auteurs.append(cols[0].text.strip())
        societes.append(cols[1].text.strip())
        annees.append(cols[2].text.strip())
        titres.append(cols[3].text.strip())

# Création d'un DataFrame
df = pd.DataFrame({
    'Auteur': auteurs,
    'Société': societes,
    'Année': annees,
    'Titre': titres
})

# Sauvegarde dans un fichier txt
with open('memoires_actuariat.txt', 'w', encoding='utf-8') as f:
    df.to_string(f, index=False)

print("Les données ont été extraites et sauvegardées dans 'memoires_actuariat.txt'")


